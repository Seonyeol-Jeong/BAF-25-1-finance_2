{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.29.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.26.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\chica\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì—°ì˜ˆì¸(ë‚˜ë¬´ìœ„í‚¤ ì‚¬ì´íŠ¸ê¹Œì§€) ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### div ì§€ì •í•´ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì‹œìš°ë¯¼\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ìˆ˜í˜¸\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì„¸í›ˆ\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ìµœê°•ì°½ë¯¼\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì˜ˆì„±\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ë™í•´\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ë ¤ìš±\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ê·œí˜„\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì¢…í˜„\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: í‚¤\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ë¯¼í˜¸\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: íƒœë¯¼\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ìœ íƒ€\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì¿¤\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ë„ì˜\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: í…\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ë§ˆí¬\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ìƒ¤ì˜¤ì¥”\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: í—¨ë“œë¦¬\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì œë…¸\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì¬ë¯¼\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì–‘ì–‘\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì²œëŸ¬\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì§€ì„±\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì‡¼íƒ€ë¡œ\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì€ì„\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì„±ì°¬\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì›ë¹ˆ\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ìŠ¹í•œ\n",
      "â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: ì•¤í†¤\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\") # ëŒì•„ê°€ëŠ” ê±°ê±° ì•ˆë³´ì´ê²Œ í•˜ëŠ” ì˜µì…˜\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)\")\n",
    "options.add_argument(\"--lang=ko_KR\")\n",
    "options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# ì—°ì˜ˆì¸ ëª©ë¡ CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "artist_df = pd.read_csv(\"JYP_ì—°ì˜ˆì¸ëª©ë¡.csv\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ CSV\n",
    "with open(\"JYPë…¼ë€_í¬ë¡¤ë§.csv\", \"w\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['ì†Œì†ì‚¬', 'ê·¸ë£¹', 'ì—°ì˜ˆì¸ ì´ë¦„', 'í…ìŠ¤íŠ¸'])\n",
    "\n",
    "    for _, artist in artist_df.iterrows():\n",
    "        url = str(artist['url']).strip()\n",
    "        \n",
    "        if not url.startswith(\"http\"):\n",
    "            # URLì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë³¸ ì •ë³´ë§Œ ê¸°ë¡\n",
    "            writer.writerow([\n",
    "                artist['ì†Œì†ì‚¬'],\n",
    "                artist['ê·¸ë£¹'],\n",
    "                artist['ì—°ì˜ˆì¸ ì´ë¦„'],\n",
    "                ''\n",
    "            ])\n",
    "            print(f\"â„¹ï¸ URL ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ì—†ì´ ê¸°ë¡: {artist['ì—°ì˜ˆì¸ ì´ë¦„']}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(3)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # BEFORE: í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸\n",
    "            # text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            # AFTER: íŠ¹ì • div í…ìŠ¤íŠ¸ë§Œ\n",
    "            target_div = soup.find(\"div\", class_=\"EyS5B+jf upriic4n\")\n",
    "            text = target_div.get_text(separator=\"\\n\", strip=True) if target_div else \"\"\n",
    "\n",
    "            writer.writerow([\n",
    "                artist['ì†Œì†ì‚¬'],\n",
    "                artist['ê·¸ë£¹'],\n",
    "                artist['ì—°ì˜ˆì¸ ì´ë¦„'],\n",
    "                text\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {artist['ì—°ì˜ˆì¸ ì´ë¦„']} â†’ {e}\")\n",
    "            writer.writerow([\n",
    "                artist['ì†Œì†ì‚¬'],\n",
    "                artist['ê·¸ë£¹'],\n",
    "                artist['ì—°ì˜ˆì¸ ì´ë¦„'],\n",
    "                ''\n",
    "            ])\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê·¸ë£¹ë¼ë¦¬ ê°™ì€ ë…¼ë€/ì‚¬ê±´ì‚¬ê³  í˜ì´ì§€ë¥¼ ê°€ì§€ëŠ” ê²½ìš°\n",
    "\n",
    "ì‹œì‘: í•´ë‹¹ í–‰ ì—°ì˜ˆì¸ ì´ë¦„\n",
    "\n",
    "ë: ê°™ì€ ê·¸ë£¹ì˜ ë‹¤ë¥¸ ì—°ì˜ˆì¸ ì´ë¦„ ê°€ì¥ ë¨¼ì € ë‚˜ì˜¤ëŠ” ê³³ ì´ì „ê¹Œì§€\n",
    "\n",
    "ì‹œì‘~ë ì´ì „ê¹Œì§€ ìŠ¬ë¼ì´ì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ê·¸ë£¹ ê¸°ì¤€ ëª©ì°¨-ì´ë¦„ ë§¤ì¹­ í…ìŠ¤íŠ¸ ì˜ë¼ë‚´ê¸° ì™„ë£Œ ë° ì €ì¥\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ìƒˆ í…ìŠ¤íŠ¸ ìë¥´ê¸° í•¨ìˆ˜\n",
    "def trim_text_by_group_using_headers(text, current_name, group_names):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    header_pattern_current = rf'\\d+(?:\\.\\d+)*\\.\\s*{re.escape(current_name)}'\n",
    "    current_match = re.search(header_pattern_current, text)\n",
    "\n",
    "    if not current_match:\n",
    "        return text\n",
    "\n",
    "    start = current_match.start()\n",
    "\n",
    "    other_names = [name for name in group_names if name != current_name]\n",
    "    other_positions = []\n",
    "    for other in other_names:\n",
    "        pattern_other = rf'\\d+(?:\\.\\d+)*\\.\\s*{re.escape(other)}'\n",
    "        match_other = re.search(pattern_other, text[start+1:])\n",
    "        if match_other:\n",
    "            other_positions.append(start + 1 + match_other.start())\n",
    "\n",
    "    end = min(other_positions) if other_positions else len(text)\n",
    "\n",
    "    return text[start:end].strip()\n",
    "\n",
    "# í¬ë¡¤ë§ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"JYPë…¼ë€_í¬ë¡¤ë§.csv\")\n",
    "artist_df = pd.read_csv(\"JYP_ì—°ì˜ˆì¸ëª©ë¡.csv\")\n",
    "\n",
    "# ê° í–‰ë§ˆë‹¤ ì ìš©\n",
    "for idx, row in df.iterrows():\n",
    "    group = row['ê·¸ë£¹']\n",
    "    name = row['ì—°ì˜ˆì¸ ì´ë¦„']\n",
    "    full_text = row['í…ìŠ¤íŠ¸']\n",
    "\n",
    "    group_names = artist_df[artist_df['ê·¸ë£¹'] == group]['ì—°ì˜ˆì¸ ì´ë¦„'].tolist()\n",
    "    trimmed = trim_text_by_group_using_headers(full_text, name, group_names)\n",
    "\n",
    "    df.at[idx, 'í…ìŠ¤íŠ¸'] = trimmed\n",
    "\n",
    "# ë‹¤ì‹œ ì €ì¥\n",
    "df.to_csv(\"JYPë…¼ë€_í¬ë¡¤ë§.csv\", index=False, encoding='utf-8-sig')\n",
    "print(\"ğŸ¯ ê·¸ë£¹ ê¸°ì¤€ ëª©ì°¨-ì´ë¦„ ë§¤ì¹­ í…ìŠ¤íŠ¸ ì˜ë¼ë‚´ê¸° ì™„ë£Œ ë° ì €ì¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.\n",
      "ì¹´ë¦¬ë‚˜\n",
      "[í¸ì§‘]\n",
      "3.1.1.\n",
      "ë°ë·” ì „ ì•…ì„± ë£¨ë¨¸ í”¼í•´\n",
      "[í¸ì§‘]\n",
      "aespaì˜ ë°ë·” ì§ì „ì— ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹° ì‚¬ì´íŠ¸ë¥¼ í†µí•´ SM ì—°ìŠµìƒ\n",
      "ìœ ì§€ë¯¼\n",
      "(ì¹´ë¦¬ë‚˜ì˜ ë³¸ëª…)ì˜ ì§€ì¸ì´ë¼ê³  ì£¼ì¥í•˜ëŠ” ëˆ„ë¦¬ê¾¼ì´ ìœ ì§€ë¯¼ê³¼ ë‚˜ëˆˆ ë¬¸ì ë©”ì‹œì§€ ë“±ì„ ê³µê°œí•´ ë…¼ë€ì´ ì¼ì–´ë‚¬ë‹¤. í•´ë‹¹ ë©”ì‹œì§€ì—ëŠ” ì„ ë°° ê°€ìˆ˜ ë° íšŒì‚¬ì™€ ê´€ë ¨í•œ ë‚´ìš©ì´ ë‹´ê²¨ ìˆì—ˆë‹¤.\n",
      "ë©”ì‹œì§€ ì¡°ì‘ ì¦ê±°\n",
      "ì´ì— ì†Œì†ì‚¬ SMì—”í„°í…Œì¸ë¨¼íŠ¸ëŠ” \"ìœ ì§€ë¯¼ ì–‘ì— ëŒ€í•œ ì•…ì„± ë£¨ë¨¸ê°€ ë¬´ë¶„ë³„í•˜ê²Œ ìœ í¬ë˜ê³  ìˆë‹¤\"ë¼ë©° í•´ë‹¹ ê¸€ì´\n",
      "í—ˆìœ„ ë° ì¡°ì‘ëœ ë‚´ìš©\n",
      "ì„ì—ë„ ë¶ˆêµ¬í•˜ê³ , ëŠì„ì—†ì´ í™•ëŒ€ ë° ì¬ìƒì‚°ë˜ê³  ìˆë‹¤ê³  ë°í˜”ë‹¤. ë˜í•œ \"ì˜¨ë¼ì¸ ìƒì—ì„œ ë²Œì–´ì§€ëŠ” ì¸ê²© ëª¨ë…, ì•…ì„± ë£¨ë¨¸ ìœ í¬ í–‰ìœ„ ë“± ë¶ˆë²• í–‰ìœ„ì— ëŒ€í•´ ë¬´ê´€ìš© ì›ì¹™í•˜ì— ë¯¼Â·í˜•ì‚¬ìƒ ë²•ì  ì¡°ì¹˜ë¥¼ ì·¨í•˜ì—¬ ëŒ€ì‘í•  ê²ƒ\"ì´ë¼ê³  ë°íˆë©° ì§€ë‚œ 10ì›” ê°•ë‚¨ê²½ì°°ì„œë¥¼ í†µí•´ ìœ ì§€ë¯¼ê³¼ ê´€ë ¨í•œ\n",
      "ì•…ì˜ì  ê²Œì‹œê¸€ì„ ì‘ì„±í•˜ëŠ” ì´ë“¤ì„ ê³ ì†Œí–ˆë‹¤\n",
      "ê³  ì „í–ˆë‹¤.\n",
      "í•œêµ­ê²½ì œ ê¸°ì‚¬\n",
      "ë˜í•œ ì¹´ë¦¬ë‚˜ì˜ ì¤‘ê³ ë“±í•™êµ ë™ì°½ ë“±ì´ ì¹´ë¦¬ë‚˜ë¥¼ ë‘˜ëŸ¬ì‹¼ ì•…ì„± ë£¨ë¨¸ì— ëŒ€í•´ ë¶€ì •í•˜ëŠ” ê¸€ì„ ì˜¬ë ¸ë‹¤.\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "ì´ ë¬¸ë‹¨ì˜ ë‚´ìš© ì¤‘ ì „ì²´ ë˜ëŠ” ì¼ë¶€ëŠ”\n",
      "ì¹´ë¦¬ë‚˜\n",
      "ë¬¸ì„œì˜\n",
      "uuid not found\n",
      "íŒ,\n",
      "6ë²ˆ ë¬¸ë‹¨\n",
      "ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n",
      "ì´ì „ ì—­ì‚¬ ë³´ëŸ¬ ê°€ê¸°\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"JYPë…¼ë€_í¬ë¡¤ë§.csv\")\n",
    "artist_text = df[df['ì—°ì˜ˆì¸ ì´ë¦„'] == 'ì¹´ë¦¬ë‚˜']['í…ìŠ¤íŠ¸'].values\n",
    "\n",
    "print(artist_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ìŠ¤íŠ¸ ì •ë¦¬\n",
    "\n",
    "`ì†Œì†ì‚¬`, `ì—°ì˜ˆì¸`, `ì‚¬ê±´ ë‚ ì§œ`, `ì‚¬ê±´ ë‚´ìš©`\n",
    "\n",
    "`ì‚¬ê±´ ë‚´ìš©`: ì œëª©ì„ í¬í•¨í•œ ëª¨ë“  í…ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ë‚ ì§œ ì •ê·œí‘œí˜„ì‹ (ì˜ˆ: 2020ë…„ 1ì›” 2ì¼ ë˜ëŠ” 2020ë…„ 01ì›” 02ì¼ ë“±)\n",
    "date_pattern = re.compile(r'\\d{4}ë…„\\s?\\d{1,2}ì›”\\s?\\d{1,2}ì¼')\n",
    "\n",
    "# ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "date_separated_data = []\n",
    "\n",
    "# ê° ì—°ì˜ˆì¸ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ì²˜ë¦¬\n",
    "for _, row in df.iterrows():\n",
    "    full_text = str(row['í…ìŠ¤íŠ¸'])  # âœ… ë¬¸ìì—´ë¡œ ë³€í™˜ (NaN ë°©ì§€)\n",
    "    matches = list(date_pattern.finditer(full_text))\n",
    "\n",
    "    if not matches:\n",
    "        date_separated_data.append({\n",
    "            'ì†Œì†ì‚¬': row['ì†Œì†ì‚¬'],\n",
    "            'ê·¸ë£¹': row['ê·¸ë£¹'],\n",
    "            'ì—°ì˜ˆì¸ ì´ë¦„': row['ì—°ì˜ˆì¸ ì´ë¦„'],\n",
    "            'ì‚¬ê±´ ë‚ ì§œ': '',\n",
    "            'ì‚¬ê±´ ë‚´ìš©': full_text.strip()\n",
    "        })\n",
    "    else:\n",
    "        for i, match in enumerate(matches):\n",
    "            start = match.start()\n",
    "            end = matches[i + 1].start() if i + 1 < len(matches) else len(full_text)\n",
    "            date = match.group()\n",
    "            content = full_text[start:end].strip()\n",
    "            date_separated_data.append({\n",
    "                'ì†Œì†ì‚¬': row['ì†Œì†ì‚¬'],\n",
    "                'ê·¸ë£¹': row['ê·¸ë£¹'],\n",
    "                'ì—°ì˜ˆì¸ ì´ë¦„': row['ì—°ì˜ˆì¸ ì´ë¦„'],\n",
    "                'ì‚¬ê±´ ë‚ ì§œ': date,\n",
    "                'ì‚¬ê±´ ë‚´ìš©': content\n",
    "            })\n",
    "\n",
    "# ê²°ê³¼ DataFrame ìƒì„± ë° ì €ì¥\n",
    "date_df = pd.DataFrame(date_separated_data)\n",
    "date_df.to_csv(\"JYPë…¼ë€_í¬ë¡¤ë§.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ì‚¬ê±´ ë‚´ìš©`: ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ëë‚˜ë©´(ë§ˆì§€ë§‰ '~ë‹¤.'ì´ ë‚˜íƒ€ë‚˜ë©´) ê·¸ ë‹¤ìŒ ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ëŠ” ì „ë¶€ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_csv('JYPë…¼ë€_í¬ë¡¤ë§.csv')\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜\n",
    "def keep_until_last_da(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "    # ë§ˆì§€ë§‰ '~ë‹¤.' ìœ„ì¹˜ ì°¾ê¸°\n",
    "    match = list(re.finditer(r'ë‹¤\\.', text))\n",
    "    if match:\n",
    "        last_match = match[-1]\n",
    "        cut_idx = last_match.end()\n",
    "        return text[:cut_idx]\n",
    "    else:\n",
    "        # '~ë‹¤.'ê°€ ì—†ëŠ” ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "        return text\n",
    "\n",
    "# ì ìš©\n",
    "df['ì‚¬ê±´ ë‚´ìš©'] = df['ì‚¬ê±´ ë‚´ìš©'].apply(keep_until_last_da)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv('JYPë…¼ë€_í¬ë¡¤ë§.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê° ì¸ë¬¼ì˜ ë§ˆì§€ë§‰ í–‰ì— ì£¼ì„ ëª°ì•„ì„œ ë“¤ì–´ê°„ê±° ë‹¤ ì‚­ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('JYPë…¼ë€_í¬ë¡¤ë§.csv')\n",
    "\n",
    "# ê° ì¸ë¬¼ì˜ ë§ˆì§€ë§‰ ì‚¬ê±´ í–‰ë§Œ ë³µì‚¬\n",
    "last_rows = df.groupby('ì—°ì˜ˆì¸ ì´ë¦„').tail(1).copy()\n",
    "\n",
    "# ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ë³µì‚¬ (ìˆ˜ì • ë°˜ì˜ìš©)\n",
    "df_copy = df.copy()\n",
    "\n",
    "# ê° ì¸ë¬¼ ë§ˆì§€ë§‰ ì‚¬ê±´ í…ìŠ¤íŠ¸ì—ì„œ '[1]' ì´í›„ ì‚­ì œ\n",
    "for idx in last_rows.index:\n",
    "    content = df_copy.at[idx, 'ì‚¬ê±´ ë‚´ìš©']\n",
    "    if pd.notna(content):\n",
    "        if '[1]' in content:\n",
    "            df_copy.at[idx, 'ì‚¬ê±´ ë‚´ìš©'] = content.split('[1]')[0].strip()\n",
    "\n",
    "# ì €ì¥\n",
    "df_copy.to_csv('JYPë…¼ë€_í¬ë¡¤ë§.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ë‹¤ ì‚­ì œ\n",
    "\n",
    "(1) '[í¸ì§‘]' ì´í›„ ë“±ì¥í•˜ëŠ” ë¬¸ë‹¨ ë²ˆí˜¸ë¶€í„° ì‚­ì œ\n",
    "\n",
    "(2) \"ìì„¸í•œ ë‚´ìš©ì€ ~ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤\" ë¬¸ì¥ ì œê±°\n",
    "\n",
    "(3) [ìˆ«ì] ê°ì£¼ ì œê±°\n",
    "\n",
    "(4) '[í¸ì§‘]' ë‹¨ì–´ ìì²´ ì œê±°\n",
    "\n",
    "(5) \"ì´ ë¬¸ì„œì˜ ë‚´ìš© ì¤‘ ì „ì²´ ë˜ëŠ” ì¼ë¶€ëŠ”\" ì´ í¬í•¨ëœ ë¬¸ì¥ ì „ì²´ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì €ì¥ íŒŒì¼: SMë…¼ë€_í¬ë¡¤ë§.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_wiki_garbage(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "\n",
    "    # ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "\n",
    "    # 1. '[í¸ì§‘]' ì• ëª©ì°¨ íŒ¨í„´ì´ ë‚˜íƒ€ë‚˜ë©´ â†’ ê±°ê¸°ì„œ ìë¥´ê¸°\n",
    "    match = re.search(r'\\d+\\.\\d+\\..+?\\[í¸ì§‘\\]', text)\n",
    "    if not match:\n",
    "        match = re.search(r'\\d+\\..+?\\[í¸ì§‘\\]', text)\n",
    "    if match:\n",
    "        text = text[:match.start()]\n",
    "\n",
    "    # 2. \"ìì„¸í•œ ë‚´ìš©ì€ ~ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤\" ì œê±°\n",
    "    text = re.sub(r'ìì„¸í•œ ë‚´ìš©ì€ .*?ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤\\.?', '', text)\n",
    "\n",
    "    # 3. [ìˆ«ì] ê°ì£¼ ì œê±°\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "\n",
    "    # 4. '[í¸ì§‘]' ë‹¨ì–´ ì œê±°\n",
    "    text = text.replace('[í¸ì§‘]', '')\n",
    "\n",
    "    # 5. \"ì´ ë¬¸ì„œì˜ ë‚´ìš© ì¤‘ ì „ì²´ ë˜ëŠ” ì¼ë¶€ëŠ”\" ì´ í¬í•¨ëœ ë¬¸ì¥ ì „ì²´ ì œê±°\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    filtered_sentences = [\n",
    "        s for s in sentences if 'ì´ ë¬¸ì„œì˜ ë‚´ìš© ì¤‘ ì „ì²´ ë˜ëŠ” ì¼ë¶€ëŠ”' not in s\n",
    "    ]\n",
    "    text = ' '.join(filtered_sentences)\n",
    "\n",
    "    # # 6. 'YYYYë…„ MMì›” DDì¼' í˜•ì‹ ì‚­ì œ\n",
    "    # text = re.sub(r'[\\s,\\.]*\\d{4}ë…„\\s*\\d{1,2}ì›”\\s*\\d{1,2}ì¼[\\s,\\.]*', ' ', text)\n",
    "\n",
    "    # 8. 'íŒŒì›Œë§í¬ ê´‘ê³ ' ë¬¸êµ¬ í¬í•¨ ì´í›„ í…ìŠ¤íŠ¸ ì „ì²´ ì œê±° \n",
    "    ad_idx = text.find('íŒŒì›Œë§í¬ ê´‘ê³ ')\n",
    "    if ad_idx != -1:\n",
    "        text = text[:ad_idx]\n",
    "\n",
    "    # 7. ê³µë°± ì •ë¦¬\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# â–¶ 2. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "input_path = 'JYPë…¼ë€_í¬ë¡¤ë§.csv'\n",
    "output_path = 'JYPë…¼ë€_í¬ë¡¤ë§.csv'\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# â–¶ 3. ì •ì œ í•¨ìˆ˜ ì ìš©\n",
    "df['ì‚¬ê±´ ë‚´ìš©'] = df['ì‚¬ê±´ ë‚´ìš©'].apply(remove_wiki_garbage)\n",
    "\n",
    "# â–¶ 5. ê²°ê³¼ ì €ì¥\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"ì •ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì €ì¥ íŒŒì¼:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… '~ë‹¤.' í˜•íƒœ í¬í•¨ëœ í–‰ë§Œ ë‚¨ê¸°ê³  ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('JYPë…¼ë€_í¬ë¡¤ë§.csv')\n",
    "\n",
    "# '~ë‹¤.' í˜•íƒœê°€ í¬í•¨ëœ í–‰ë§Œ ë‚¨ê¸°ê¸°\n",
    "pattern = r'\\b[ê°€-í£]*ë‹¤\\.'\n",
    "df = df[df['ì‚¬ê±´ ë‚´ìš©'].str.contains(pattern, regex=True, na=False)]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv('JYPë…¼ë€_í¬ë¡¤ë§.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… '~ë‹¤.' í˜•íƒœ í¬í•¨ëœ í–‰ë§Œ ë‚¨ê¸°ê³  ì €ì¥ ì™„ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
